# app_gripandreview_online.py
"""
GripAndReview Online Bot (v5)
------------------------------
Versi Streamlit Cloud yang sudah aktif untuk:
1ï¸âƒ£ Scrape Transcript
2ï¸âƒ£ Scrape Comments

Selanjutnya akan diintegrasikan:
3ï¸âƒ£ Generate Articles (Groq)
4ï¸âƒ£ Combine Articles
5ï¸âƒ£ Render Template HTML
"""

import streamlit as st
import time

from config import (
    GROQ_API_KEY,
    GROQ_MODEL,
    GCP_SERVICE_ACCOUNT_JSON,
    DEFAULT_SHEET_NAME,
)

# Import modul pencarian & fetcher (versi online)
from yt_search_online import (
    search_youtube_online,
    fetch_comments_online,
    save_results_to_session,
)
from yt_fetcher_online import fetch_multiple_transcripts

# ======================================
# âš™ï¸ SETUP
# ======================================
st.set_page_config(page_title="GripAndReview Online Bot", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ¤– GripAndReview AI â€” Online Bot (v5.1)")
st.caption("YouTube Review Automation â€¢ Streamlit Cloud + Groq + Google Sheets")

# Sidebar status
st.sidebar.header("Integrasi")
st.sidebar.markdown(f"**Groq API Key:** {'âœ… OK' if GROQ_API_KEY else 'âŒ Missing'}")
st.sidebar.markdown(f"**Google Sheets:** {'âœ… OK' if GCP_SERVICE_ACCOUNT_JSON else 'âŒ Missing'}")
st.sidebar.markdown(f"**Default Sheet:** `{DEFAULT_SHEET_NAME}`")
st.sidebar.divider()
st.sidebar.info("Tab 1 & 2 sudah aktif (scrape YouTube transcript dan komentar).")

# ======================================
# ğŸ§© TAB SETUP
# ======================================
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ¬ Scrape Transcript",
    "ğŸ’¬ Scrape Comments",
    "ğŸ§  Generate Articles",
    "ğŸ“° Combine Articles",
    "ğŸ§© Render Template"
])

# ======================================
# TAB 1 â€” ğŸ¬ Scrape Transcript
# ======================================
with tab1:
    st.header("ğŸ¬ Scrape Transcript (YouTube)")

    st.info("Ambil daftar video dan transcript dari YouTube (maksimal 20 video).")

    keyword = st.text_input("ğŸ” Masukkan keyword pencarian:", "")
    limit = st.slider("Jumlah video:", 5, 20, 10)

    if st.button("ğŸš€ Cari Video di YouTube"):
        if not keyword.strip():
            st.warning("Masukkan keyword terlebih dahulu.")
        else:
            with st.spinner(f"Mencari '{keyword}' di YouTube..."):
                try:
                    results = search_youtube_online(keyword, max_results=limit)
                    save_results_to_session(results)
                    st.session_state["videos"] = results
                    st.success(f"âœ… Ditemukan {len(results)} video.")
                except Exception as e:
                    st.error(f"âŒ Gagal mencari video: {e}")

    if "videos" in st.session_state:
        videos = st.session_state["videos"]
        st.subheader("ğŸ“‹ Daftar Video Ditemukan:")
        st.dataframe(videos)

        if st.button("ğŸ“œ Ambil Transcript Semua Video"):
            with st.spinner("Mengambil transcript..."):
                transcripts = fetch_multiple_transcripts(videos, limit=len(videos))
            st.session_state["transcripts"] = transcripts
            st.success(f"âœ… {len(transcripts)} transcript berhasil diambil.")

        if "transcripts" in st.session_state:
            st.subheader("ğŸ“– Contoh Transcript (1 Video):")
            any_url = list(st.session_state["transcripts"].keys())[0]
            st.text_area("Sample Transcript", st.session_state["transcripts"][any_url][:1000], height=250)

    else:
        st.warning("Belum ada hasil pencarian. Jalankan pencarian dulu.")

# ======================================
# TAB 2 â€” ğŸ’¬ Scrape Comments
# ======================================
with tab2:
    st.header("ğŸ’¬ Scrape Comments")

    st.info("Ambil komentar YouTube dari daftar video yang sudah ditemukan di Tab 1.")
    max_comments = st.slider("Maksimum komentar per video", 10, 200, 50, step=10)

    if "videos" not in st.session_state:
        st.warning("Belum ada video. Jalankan pencarian dulu di Tab 1.")
    else:
        videos = st.session_state["videos"]
        if st.button("â¬‡ï¸ Ambil Komentar Semua Video"):
            all_comments = {}
            progress = st.progress(0)
            for idx, v in enumerate(videos):
                st.write(f"ğŸ“¥ Mengambil komentar dari: {v['judul']}")
                comments = fetch_comments_online(v["url"], max_comments=max_comments)
                all_comments[v["url"]] = comments
                progress.progress((idx + 1) / len(videos))
            st.session_state["comments"] = all_comments
            st.success(f"âœ… Komentar berhasil diambil dari {len(all_comments)} video.")

        if "comments" in st.session_state:
            st.subheader("ğŸ—¨ï¸ Contoh Komentar (1 Video):")
            any_url = list(st.session_state["comments"].keys())[0]
            sample_comments = "\n".join(st.session_state["comments"][any_url][:10])
            st.text_area("Sample Comments", sample_comments, height=200)

# ======================================
# TAB 3 â€” ğŸ§  Generate Articles (coming soon)
# ======================================
with tab3:
    st.header("ğŸ§  Generate Articles (AI)")
    st.info("Akan menggunakan Groq API untuk membuat artikel otomatis dari transcript + komentar.")
    st.write("ğŸ’¤ Fitur ini akan diaktifkan setelah Tab 1 & 2 stabil.")

# ======================================
# TAB 4 â€” ğŸ“° Combine Articles (coming soon)
# ======================================
with tab4:
    st.header("ğŸ“° Combine Articles")
    st.info("Akan menggabungkan artikel menjadi satu kesatuan menggunakan AI.")
    st.write("ğŸ’¤ Fitur ini akan diaktifkan setelah modul summarizer siap.")

# ======================================
# TAB 5 â€” ğŸ§© Render Template HTML (coming soon)
# ======================================
with tab5:
    st.header("ğŸ§© Render Template HTML")
    st.info("Akan mengubah hasil gabungan artikel menjadi template HTML siap posting.")
    st.write("ğŸ’¤ Fitur ini akan diaktifkan setelah renderer AI selesai.")

# ======================================
# ğŸ§­ FOOTER
# ======================================
st.divider()
st.caption("GripAndReview Online Bot â€” powered by Streamlit Cloud + Groq + Google Sheets")
